{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNYQ8roCW8pX+jg4nRsppIH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navneeth08k/dayTradingModel/blob/main/DayTrading_Full_RL_approach_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Project by Navneeth Krishna**\n",
        "\n",
        "**Reinforcement Learning model to learn how to day trade stocks**\n",
        "\n",
        "\n",
        "Treat a day of stock trading as a game/puzzle where you have to figure out when\n",
        "a stock will rise and fall. Reward for return, penalty for failures.\n"
      ],
      "metadata": {
        "id": "2bE3RuV72nst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "My approach here was fully Reinforcement Learning, where I train the model to only predict apple stock.\n",
        "\n",
        "Pros: Will be really good (hopefully) at predicting apple stock changes, will be able to find a pattern in this stock\n",
        "\n",
        "Cons: Will not be generalizable to other stocks (probably), may not find the real patterns that analyzers use. Daytraders often see patterns in a variety of stocks which is what enables them to make their predictions of whether or not a stock will go up or down."
      ],
      "metadata": {
        "id": "QNsrquua1orw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install dependencies\n",
        "!pip install gymnasium stable-baselines3 numpy pandas matplotlib"
      ],
      "metadata": {
        "id": "Lr9dJ0hq3MAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.env_checker import check_env\n"
      ],
      "metadata": {
        "id": "fmB2FjD04HWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta\n"
      ],
      "metadata": {
        "id": "n0FkIYjkUAek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import necessary libraries\n",
        "!pip install yfinance ta\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "\n",
        "# 1. Download Apple intraday data\n",
        "df = yf.download('AAPL', start='2024-10-01', end='2024-11-10', interval='5m')\n",
        "\n",
        "# 2. Check the columns before flattening\n",
        "print(\"Columns before flattening:\", df.columns)\n",
        "\n",
        "# 3. Properly flatten the MultiIndex columns by joining the levels\n",
        "df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in df.columns]\n",
        "\n",
        "# 4. Rename columns for clarity\n",
        "df.rename(columns={\n",
        "    'Adj Close_AAPL': 'Adj_Close',\n",
        "    'Close_AAPL': 'Close',\n",
        "    'High_AAPL': 'High',\n",
        "    'Low_AAPL': 'Low',\n",
        "    'Open_AAPL': 'Open',\n",
        "    'Volume_AAPL': 'Volume'\n",
        "}, inplace=True)\n",
        "\n",
        "# 5. Verify the column names\n",
        "print(\"Columns after renaming:\", df.columns)\n",
        "\n",
        "# 6. Check for missing values\n",
        "print(\"Missing values before cleaning:\", df.isna().sum())\n",
        "\n",
        "# 7. Fill missing values using forward-fill and back-fill, then drop remaining NaNs\n",
        "df.ffill(inplace=True)\n",
        "df.bfill(inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 8. Verify the DataFrame is not empty and check its length\n",
        "print(\"DataFrame length after cleaning:\", len(df))\n",
        "if len(df) == 0:\n",
        "    raise ValueError(\"DataFrame is empty after preprocessing. Please check the input data.\")\n",
        "\n",
        "# 9. Prepare the data for indicator calculations\n",
        "high_prices = df['High'].astype(float)\n",
        "low_prices = df['Low'].astype(float)\n",
        "close_prices = df['Close'].astype(float)\n",
        "\n",
        "# 10. Calculate technical indicators\n",
        "\n",
        "# Short-Term Moving Averages\n",
        "df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
        "df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()\n",
        "\n",
        "# Volume-Weighted Average Price (VWAP)\n",
        "df['VWAP'] = (df['Volume'] * (df['High'] + df['Low'] + df['Close']) / 3).cumsum() / df['Volume'].cumsum()\n",
        "\n",
        "# Short-Term RSI (7-period)\n",
        "rsi_short = ta.momentum.RSIIndicator(close=close_prices, window=7)\n",
        "df['RSI_7'] = rsi_short.rsi()\n",
        "\n",
        "# Intraday Momentum Index (IMI)\n",
        "df['Up'] = np.where(df['Close'] > df['Open'], df['Close'] - df['Open'], 0)\n",
        "df['Down'] = np.where(df['Close'] < df['Open'], df['Open'] - df['Close'], 0)\n",
        "df['IMI'] = 100 * (df['Up'].rolling(window=14).sum() / (df['Up'].rolling(window=14).sum() + df['Down'].rolling(window=14).sum()))\n",
        "\n",
        "# Average True Range (ATR)\n",
        "atr_indicator = ta.volatility.AverageTrueRange(high=high_prices, low=low_prices, close=close_prices, window=14)\n",
        "df['ATR'] = atr_indicator.average_true_range()\n",
        "\n",
        "# Stochastic Oscillator\n",
        "stochastic = ta.momentum.StochasticOscillator(high=high_prices, low=low_prices, close=close_prices, window=14, smooth_window=3)\n",
        "df['Stoch_K'] = stochastic.stoch()\n",
        "df['Stoch_D'] = stochastic.stoch_signal()\n",
        "\n",
        "# 11. Check for NaNs and fill them again\n",
        "print(\"Missing values before final cleaning:\", df.isna().sum())\n",
        "df.ffill(inplace=True)\n",
        "df.bfill(inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 12. Verify the DataFrame is not empty and display the first few rows\n",
        "print(\"DataFrame length after final cleaning:\", len(df))\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "ETx_H-g8UE-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class StockTradingEnv(gym.Env):\n",
        "    def __init__(self, df, max_episode_length=500, cooldown_period=5):\n",
        "        super(StockTradingEnv, self).__init__()\n",
        "        self.df = df\n",
        "        self.trading_days = self.df.index.normalize().unique()\n",
        "        self.current_day = None\n",
        "        self.current_step = 0\n",
        "        self.initial_balance = 10000\n",
        "        self.balance = self.initial_balance\n",
        "        self.shares_held = 0\n",
        "        self.total_profit = 0\n",
        "        self.cooldown_period = cooldown_period\n",
        "        self.cooldown_counter = 0\n",
        "        self.can_buy = True  # Enforce a buy-sell cycle\n",
        "\n",
        "        # Define action and observation space\n",
        "        self.action_space = spaces.Discrete(3)  # Actions: 0 = Hold, 1 = Buy, 2 = Sell\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(14,), dtype=np.float32)\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "      super().reset(seed=seed)\n",
        "\n",
        "      # Randomly select a trading day for the episode\n",
        "      self.current_day = np.random.choice(self.trading_days)\n",
        "      self.day_data = self.df[self.df.index.normalize() == self.current_day]\n",
        "      self.current_step = 0\n",
        "      self.balance = self.initial_balance\n",
        "      self.shares_held = 0\n",
        "      self.total_profit = 0\n",
        "      self.last_buy_price = 0  # Initialize last_buy_price to 0\n",
        "      self.can_buy = True  # Start with the ability to buy\n",
        "\n",
        "      observation = self._next_observation()\n",
        "      return observation, {}\n",
        "\n",
        "\n",
        "    def _next_observation(self):\n",
        "        frame = np.array([\n",
        "            float(self.day_data.iloc[self.current_step]['Open']) / 1000,\n",
        "            float(self.day_data.iloc[self.current_step]['High']) / 1000,\n",
        "            float(self.day_data.iloc[self.current_step]['Low']) / 1000,\n",
        "            float(self.day_data.iloc[self.current_step]['Close']) / 1000,\n",
        "            self.balance / 10000,\n",
        "            self.shares_held / 10,\n",
        "            float(self.day_data.iloc[self.current_step]['SMA_5']) / 1000,\n",
        "            float(self.day_data.iloc[self.current_step]['EMA_10']) / 1000,\n",
        "            float(self.day_data.iloc[self.current_step]['VWAP']) / 1000,\n",
        "            float(self.day_data.iloc[self.current_step]['RSI_7']) / 100,\n",
        "            float(self.day_data.iloc[self.current_step]['IMI']) / 100,\n",
        "            float(self.day_data.iloc[self.current_step]['ATR']) / 1000,\n",
        "            float(self.day_data.iloc[self.current_step]['Stoch_K']) / 100,\n",
        "            float(self.day_data.iloc[self.current_step]['Stoch_D']) / 100,\n",
        "        ], dtype=np.float32)\n",
        "        return frame\n",
        "\n",
        "    def step(self, action):\n",
        "      current_price = float(self.day_data.iloc[self.current_step]['Close'])\n",
        "      reward = 0.0\n",
        "      transaction_cost = 0.001  # 0.1% transaction cost\n",
        "      min_profit_threshold = current_price * 0.01  # 1% minimum profit threshold\n",
        "\n",
        "      # Cooldown mechanism to prevent overtrading\n",
        "      if self.cooldown_counter > 0:\n",
        "          action = 0  # Force hold action during cooldown\n",
        "          self.cooldown_counter -= 1\n",
        "\n",
        "      # Execute action: 0 = Hold, 1 = Buy, 2 = Sell\n",
        "      if self.can_buy:\n",
        "          if action == 1 and self.balance >= current_price:  # Buy action\n",
        "              self.shares_held += 1\n",
        "              self.balance -= current_price * (1 + transaction_cost)\n",
        "              self.last_buy_price = current_price\n",
        "              self.can_buy = False  # Now the model must sell before it can buy again\n",
        "              self.cooldown_counter = self.cooldown_period\n",
        "\n",
        "      if not self.can_buy:  # Only allow sell after a buy\n",
        "          if action == 2 and self.shares_held > 0:  # Sell action\n",
        "              self.shares_held -= 1\n",
        "              self.balance += current_price * (1 - transaction_cost)\n",
        "\n",
        "              # Calculate trade profit\n",
        "              trade_profit = current_price - self.last_buy_price - (2 * transaction_cost * current_price)\n",
        "\n",
        "              # Reward only if the trade was profitable above the threshold\n",
        "              if trade_profit > min_profit_threshold:\n",
        "                  reward = trade_profit * 1.1\n",
        "              else:\n",
        "                  reward = -1.0  # Increased penalty for unprofitable trades\n",
        "\n",
        "              self.can_buy = True  # Now the model can buy again\n",
        "              self.cooldown_counter = self.cooldown_period\n",
        "\n",
        "      # Reward for holding during an uptrend\n",
        "      if action == 0 and not self.can_buy and current_price > self.last_buy_price:\n",
        "          reward += 0.05\n",
        "\n",
        "      # Update current step\n",
        "      self.current_step += 1\n",
        "\n",
        "      # Check if the episode is done\n",
        "      done = self.current_step >= len(self.day_data) - 1\n",
        "      truncated = False\n",
        "\n",
        "      # **Do Not Automatically Sell at End of Episode**\n",
        "      # Comment out any forced sell at the end of the episode.\n",
        "\n",
        "      # Calculate total value (balance + value of held shares)\n",
        "      total_value = self.balance + self.shares_held * current_price\n",
        "      realized_profit = self.balance - self.initial_balance  # Only from balance\n",
        "      unrealized_profit = total_value - self.initial_balance\n",
        "\n",
        "      # Add a small reward for increasing realized profit\n",
        "      reward += realized_profit * 0.002\n",
        "\n",
        "      return self._next_observation(), reward, done, truncated, {\n",
        "          \"realized_profit\": realized_profit,\n",
        "          \"unrealized_profit\": unrealized_profit,\n",
        "          \"shares_held\": self.shares_held,\n",
        "      }\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        total_value = self.balance + self.shares_held * float(self.day_data.iloc[self.current_step]['Close'])\n",
        "        print(f'Step: {self.current_step}')\n",
        "        print(f'Balance: {self.balance:.2f}')\n",
        "        print(f'Shares Held: {self.shares_held}')\n",
        "        print(f'Total Value: {total_value:.2f}')\n",
        "        print(f'Total Profit: {total_value - self.initial_balance:.2f}')\n"
      ],
      "metadata": {
        "id": "tofnNxhB4ZYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import gym\n",
        "\n",
        "# Initialize the custom StockTradingEnv environment\n",
        "env = StockTradingEnv(df)\n",
        "\n",
        "# Verify the environment using Stable-Baselines3's `check_env`\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "# Check if the environment is properly set up\n",
        "check_env(env)\n",
        "\n",
        "# Reset the environment to get the initial observation\n",
        "observation, info = env.reset()\n",
        "print(\"Initial Observation:\", observation)\n"
      ],
      "metadata": {
        "id": "qPOeD37V4w50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "\n",
        "# Wrap the environment with Monitor for logging\n",
        "env = Monitor(StockTradingEnv(df))\n",
        "\n",
        "# Initialize the DQN model with the environment\n",
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    learning_rate=0.00005,\n",
        "    exploration_fraction=0.45,\n",
        "    exploration_final_eps=0.05\n",
        ")\n",
        "\n",
        "\n",
        "# Define a callback to log episode rewards\n",
        "class RewardLoggingCallback(BaseCallback):\n",
        "    def __init__(self):\n",
        "        super(RewardLoggingCallback, self).__init__()\n",
        "        self.episode_rewards = []\n",
        "        self.episode_reward = 0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        # Accumulate rewards for the current episode\n",
        "        self.episode_reward += self.locals['rewards']\n",
        "\n",
        "        # Check if the episode is done\n",
        "        if self.locals['dones']:\n",
        "            # Log the total reward for the episode\n",
        "            self.episode_rewards.append(self.episode_reward)\n",
        "            # Reset the episode reward\n",
        "            self.episode_reward = 0\n",
        "        return True\n",
        "\n",
        "# Initialize the callback\n",
        "reward_callback = RewardLoggingCallback()\n",
        "\n",
        "# Train the model with the callback\n",
        "\n",
        "model.learn(total_timesteps=1000000, callback=reward_callback)\n",
        "\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"dqn_stock_trading_model\")\n",
        "print(\"Training completed and model saved.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tcfBzYa640lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the learning curve\n",
        "if len(reward_callback.episode_rewards) > 0:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(reward_callback.episode_rewards, label='Episode Reward')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "    plt.title('Learning Curve: Model Performance Over Training Episodes')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No rewards logged. Try increasing the number of timesteps or reducing episode length.\")\n"
      ],
      "metadata": {
        "id": "ZCzVCvQ9krZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Number of random test days\n",
        "num_test_days = 5\n",
        "\n",
        "# Get unique trading days from the DataFrame\n",
        "trading_days = df.index.normalize().unique()\n",
        "random_test_days = random.sample(list(trading_days), num_test_days)\n",
        "\n",
        "# Variables to store aggregated results\n",
        "total_model_profit = 0\n",
        "total_buy_and_hold_profit = 0\n",
        "\n",
        "# Iterate through each randomly selected test day\n",
        "for test_day in random_test_days:\n",
        "    print(f\"Testing on {test_day.date()}\")\n",
        "\n",
        "    # Filter data for the selected trading day\n",
        "    test_df = df[df.index.normalize() == test_day]\n",
        "    if test_df.empty:\n",
        "        print(\"No data available for this day, skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Initialize the environment for testing\n",
        "    test_env = StockTradingEnv(test_df)\n",
        "    obs, _ = test_env.reset()\n",
        "\n",
        "    # Variables for visualization and performance tracking\n",
        "    balance_history = []\n",
        "    stock_price_history = []\n",
        "    profit_history = []\n",
        "    buy_points = []\n",
        "    sell_points = []\n",
        "    previous_action = None\n",
        "\n",
        "    done = False\n",
        "    initial_balance = test_env.initial_balance\n",
        "\n",
        "    # Calculate buy-and-hold profit\n",
        "    buy_and_hold_start_price = float(test_df.iloc[0]['Open'])\n",
        "    buy_and_hold_end_price = float(test_df.iloc[-1]['Close'])\n",
        "    buy_and_hold_profit = buy_and_hold_end_price - buy_and_hold_start_price\n",
        "\n",
        "    # Test the model on the selected day\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, truncated, info = test_env.step(action)\n",
        "\n",
        "        # Record current stock price and balance\n",
        "        current_price = float(test_df.iloc[test_env.current_step]['Close'])\n",
        "        stock_price_history.append(current_price)\n",
        "        balance_history.append(test_env.balance)\n",
        "\n",
        "        # Calculate the total profit from the model's strategy\n",
        "        total_value = test_env.balance + test_env.shares_held * current_price\n",
        "        model_profit = total_value - initial_balance\n",
        "        profit_history.append(model_profit)\n",
        "\n",
        "        # Record buy and sell points\n",
        "        if action == 1 and previous_action != 1:  # Buy action\n",
        "            buy_points.append((test_env.current_step, current_price))\n",
        "        elif action == 2 and previous_action != 2:  # Sell action\n",
        "            sell_points.append((test_env.current_step, current_price))\n",
        "\n",
        "        previous_action = action\n",
        "\n",
        "    # Calculate final model profit\n",
        "    final_model_profit = profit_history[-1]\n",
        "    total_model_profit += final_model_profit\n",
        "    total_buy_and_hold_profit += buy_and_hold_profit\n",
        "\n",
        "    # Print the results for this day\n",
        "    print(f\"Model Profit: ${final_model_profit:.2f}\")\n",
        "    print(f\"Buy-and-Hold Profit: ${buy_and_hold_profit:.2f}\")\n",
        "    print(f\"Stock open: ${buy_and_hold_start_price:.2f}\")\n",
        "    # Visualization for each day\n",
        "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
        "    ax1.set_xlabel('Time Step')\n",
        "    ax1.set_ylabel('Stock Price ($)', color='blue')\n",
        "    ax1.plot(stock_price_history, label='Stock Price', color='blue', alpha=0.6)\n",
        "    ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    if buy_points:\n",
        "        ax1.scatter(*zip(*buy_points), color='green', marker='^', s=100, label='Buy Signal', alpha=0.8)\n",
        "    if sell_points:\n",
        "        ax1.scatter(*zip(*sell_points), color='red', marker='v', s=100, label='Sell Signal', alpha=0.8)\n",
        "\n",
        "    # Plot model's profit on the second y-axis\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel('Profit ($)', color='green')\n",
        "    ax2.plot(profit_history, label='Model Profit', color='green', alpha=0.8)\n",
        "    ax2.tick_params(axis='y', labelcolor='green')\n",
        "\n",
        "    # Add a horizontal line for buy-and-hold profit\n",
        "    ax2.axhline(y=buy_and_hold_profit, color='purple', linestyle='--', label='Buy-and-Hold Profit')\n",
        "\n",
        "    # Combine legends for clarity\n",
        "    handles1, labels1 = ax1.get_legend_handles_labels()\n",
        "    handles2, labels2 = ax2.get_legend_handles_labels()\n",
        "    ax1.legend(handles1 + handles2, labels1 + labels2, loc='upper left')\n",
        "\n",
        "    # Adding title and grid\n",
        "    plt.title(f'Stock Price vs Model Profit with Buy/Sell Signals on {test_day.date()}')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Print aggregated results\n",
        "print(f\"\\nAggregated Results Over {num_test_days} Random Days:\")\n",
        "print(f\"Total Model Profit: ${total_model_profit:.2f}\")\n",
        "print(f\"Total Buy-and-Hold Profit: ${total_buy_and_hold_profit:.2f}\")\n",
        "\n",
        "\n",
        "if total_model_profit > total_buy_and_hold_profit:\n",
        "    print(\"The model outperformed the buy-and-hold strategy overall.\")\n",
        "else:\n",
        "    print(\"The model underperformed compared to the buy-and-hold strategy overall.\")\n"
      ],
      "metadata": {
        "id": "ogXJkt3L9sPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('dqn_stock_trading_model.p5')"
      ],
      "metadata": {
        "id": "hZewIAqwZBlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}